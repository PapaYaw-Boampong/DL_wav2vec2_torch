{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwEN3H47xSGB"
      },
      "outputs": [],
      "source": [
        "!pip install mltu\n",
        "!pip install opencv-python\n",
        "!pip install opencv-python-headless\n",
        "!pip install onnx\n",
        "!pip install torch==1.13.1+cu111\n",
        "!pip install transformers==4.33.1\n",
        "!pip install onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3VXK9DtxSGB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import Wav2Vec2ForCTC\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QyjL1YQxSGC"
      },
      "outputs": [],
      "source": [
        "import mltu\n",
        "from mltu.torch.model import Model\n",
        "from mltu.torch.losses import CTCLoss\n",
        "from mltu.torch.dataProvider import DataProvider\n",
        "from mltu.torch.metrics import CERMetric, WERMetric\n",
        "from mltu.torch.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Model2onnx, WarmupCosineDecay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmnH9zf_xSGC"
      },
      "source": [
        "from mltu.augmentors import RandomAudioNoise, RandomAudioPitchShift, RandomAudioTimeStretch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBwqSy_dxSGD"
      },
      "outputs": [],
      "source": [
        "from mltu.preprocessors import AudioReader\n",
        "from mltu.transformers import LabelIndexer, LabelPadding, AudioPadding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mltu.configs import BaseModelConfigs\n",
        "\n",
        "class ModelConfigs(BaseModelConfigs):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model_path = os.path.join(\n",
        "            \"Models/10_wav2vec2_torch\",\n",
        "            datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"),\n",
        "        )\n",
        "        self.batch_size = 8\n",
        "        self.train_epochs = 60\n",
        "        self.train_workers = 20\n",
        "\n",
        "        self.init_lr = 1.0e-8\n",
        "        self.lr_after_warmup = 1e-05\n",
        "        self.final_lr = 5e-06\n",
        "        self.warmup_epochs = 10\n",
        "        self.decay_epochs = 40\n",
        "        self.weight_decay = 0.005\n",
        "        self.mixed_precision = True\n",
        "\n",
        "        self.max_audio_length = 246000\n",
        "        self.max_label_length = 256\n",
        "\n",
        "        self.vocab = [' ', \"'\", 'a', 'b', 'c', 'd', 'e', 'ɛ', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'ɔ','p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
      ],
      "metadata": {
        "id": "2LnvAB5j2CR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnX6frN5xSGD"
      },
      "outputs": [],
      "source": [
        "configs = ModelConfigs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmBwHA07xSGE"
      },
      "source": [
        "Dataset Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtX0UIdCxSGE"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"Datasets/ahshanti_wav\"\n",
        "metadata_path = os.path.join(dataset_path, \"data.csv\")\n",
        "wavs_path = os.path.join(dataset_path, \"wavs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9-bE54wxSGE"
      },
      "source": [
        "Read metadata file and parse it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fJ51UG9xSGE"
      },
      "outputs": [],
      "source": [
        "metadata_df = pd.read_csv(metadata_path, sep=\"\\t\", header=None, quoting=3)\n",
        "dataset = []\n",
        "vocab = [' ', \"'\", 'a', 'b', 'c', 'd', 'e','ɛ', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'ɔ','p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtX7lzD3xSGF"
      },
      "outputs": [],
      "source": [
        "metadata_df['Audio Filepath'] = metadata_df['Audio Filepath'].str.replace('.ogg', '.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdP_m7fExSGF"
      },
      "source": [
        "Remove the 'Unnamed: 0' column if it exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaVqBdtjxSGF"
      },
      "outputs": [],
      "source": [
        "if 'Unnamed: 0' in metadata_df.columns:\n",
        "    metadata_df.drop(columns=['Unnamed: 0'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmVvc1SjxSGF"
      },
      "outputs": [],
      "source": [
        "for file_name, transcription, _ in metadata_df.values.tolist():\n",
        "    path = f\"Datasets/ashanti_wav/wavs/{file_name}.wav\"\n",
        "    new_label = \"\".join([l for l in transcription.lower() if l in vocab])\n",
        "    dataset.append([path, new_label])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgruZsqOxSGF"
      },
      "source": [
        "Create a data provider for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhJ2hNL9xSGF"
      },
      "outputs": [],
      "source": [
        "data_provider = DataProvider(\n",
        "    dataset=dataset,\n",
        "    skip_validation=True,\n",
        "    batch_size=configs.batch_size,\n",
        "    data_preprocessors=[\n",
        "        AudioReader(sample_rate=16000),\n",
        "        ],\n",
        "    transformers=[\n",
        "        LabelIndexer(vocab),],\n",
        "    use_cache=False,\n",
        "    batch_postprocessors=[\n",
        "        AudioPadding(max_audio_length=configs.max_audio_length, padding_value=0, use_on_batch=True),\n",
        "        LabelPadding(padding_value=len(vocab), use_on_batch=True),\n",
        "    ],\n",
        "    use_multiprocessing=True,\n",
        "    max_queue_size=10,\n",
        "    workers=configs.train_workers,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y6Fxz2SxSGF"
      },
      "outputs": [],
      "source": [
        "train_dataProvider, test_dataProvider = data_provider.split(split=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0ToaA_MxSGF"
      },
      "source": [
        "train_dataProvider.augmentors = [<br>\n",
        "        RandomAudioNoise(), <br>\n",
        "        RandomAudioPitchShift(), <br>\n",
        "        RandomAudioTimeStretch()<br>\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWBsbSS_xSGF"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(vocab)\n",
        "configs.vocab = vocab\n",
        "configs.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLjGwGEoxSGG"
      },
      "outputs": [],
      "source": [
        "class CustomWav2Vec2Model(nn.Module):\n",
        "    def __init__(self, hidden_states, dropout_rate=0.2, **kwargs):\n",
        "        super(CustomWav2Vec2Model, self).__init__( **kwargs)\n",
        "        pretrained_name = \"facebook/wav2vec2-base-960h\"\n",
        "        self.model = Wav2Vec2ForCTC.from_pretrained(pretrained_name, vocab_size=hidden_states, ignore_mismatched_sizes=True)\n",
        "        self.model.freeze_feature_encoder() # this part does not need to be fine-tuned\n",
        "    def forward(self, inputs):\n",
        "        output = self.model(inputs, attention_mask=None).logits\n",
        "        # Apply softmax\n",
        "        output = F.log_softmax(output, -1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3n3MQcJxSGG"
      },
      "outputs": [],
      "source": [
        "custom_model = CustomWav2Vec2Model(hidden_states = len(vocab)+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rWK3tiwxSGG"
      },
      "source": [
        "put on cuda device if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fWIer5jxSGG"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    custom_model = custom_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-oLImsExSGG"
      },
      "source": [
        "create callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzY8GSZOxSGG"
      },
      "outputs": [],
      "source": [
        "warmupCosineDecay = WarmupCosineDecay(\n",
        "    lr_after_warmup=configs.lr_after_warmup,\n",
        "    warmup_epochs=configs.warmup_epochs,\n",
        "    decay_epochs=configs.decay_epochs,\n",
        "    final_lr=configs.final_lr,\n",
        "    initial_lr=configs.init_lr,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEwGmx3dxSGG"
      },
      "outputs": [],
      "source": [
        "tb_callback = TensorBoard(configs.model_path + \"/logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsBgWBroxSGG"
      },
      "outputs": [],
      "source": [
        "earlyStopping = EarlyStopping(monitor=\"val_CER\", patience=16, mode=\"min\", verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eA5OYhExSGG"
      },
      "outputs": [],
      "source": [
        "modelCheckpoint = ModelCheckpoint(configs.model_path + \"/model.pt\", monitor=\"val_CER\", mode=\"min\", save_best_only=True, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKn2p7DSxSGG"
      },
      "outputs": [],
      "source": [
        "model2onnx = Model2onnx(\n",
        "    saved_model_path=configs.model_path + \"/model.pt\",\n",
        "    input_shape=(1, configs.max_audio_length),\n",
        "    verbose=1,\n",
        "    metadata={\"vocab\": configs.vocab},\n",
        "    dynamic_axes={\"input\": {0: \"batch_size\", 1: \"sequence_length\"}, \"output\": {0: \"batch_size\", 1: \"sequence_length\"}}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqSi7rrlxSGG"
      },
      "source": [
        "create model object that will handle training and testing of the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFzAY8xXxSGG"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    custom_model,\n",
        "    loss = CTCLoss(blank=len(configs.vocab), zero_infinity=True),\n",
        "    optimizer = torch.optim.AdamW(custom_model.parameters(), lr=configs.init_lr, weight_decay=configs.weight_decay),\n",
        "    metrics=[\n",
        "        CERMetric(configs.vocab),\n",
        "        WERMetric(configs.vocab)\n",
        "    ],\n",
        "    mixed_precision=configs.mixed_precision,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c8HzKvixSGG"
      },
      "source": [
        "Save training and validation datasets as csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9L-AsICxSGH"
      },
      "outputs": [],
      "source": [
        "train_dataProvider.to_csv(os.path.join(configs.model_path, \"train.csv\"))\n",
        "test_dataProvider.to_csv(os.path.join(configs.model_path, \"val.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwmIvUvmxSGH"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    train_dataProvider,\n",
        "    test_dataProvider,\n",
        "    epochs=configs.train_epochs,\n",
        "    callbacks=[\n",
        "        warmupCosineDecay,\n",
        "        tb_callback,\n",
        "        earlyStopping,\n",
        "        modelCheckpoint,\n",
        "        model2onnx\n",
        "    ]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}